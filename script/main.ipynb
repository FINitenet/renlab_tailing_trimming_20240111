{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import pysam\n",
    "import gzip\n",
    "import subprocess\n",
    "import datetime\n",
    "import tqdm\n",
    "from Bio import SeqIO, bgzf\n",
    "from Bio.Seq import Seq, reverse_complement\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "\n",
    "import csv\n",
    "import argparse\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from multiprocessing import Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-14 23:11:33.221862] Start to trim the adapter and low quality reads!\n",
      "Analysis complete for h_PB1_231215N_S36_L002_R1_001_trimmed.fq.gz\n"
     ]
    }
   ],
   "source": [
    "class Preprocess:\n",
    "    def __init__(self, input_file, output_file, tmp_path, adapter, sample_name, flag):\n",
    "        self.input_file = input_file\n",
    "        self.output_file = output_file\n",
    "        self.tmp_path = tmp_path    \n",
    "        self.adapter = adapter\n",
    "        self.sample_name = sample_name\n",
    "        self.flag = flag\n",
    "        self.log_file = os.path.join(tmp_path, \"log.txt\")\n",
    "\n",
    "    def MeanPhredScore(self, trimmed_quality):\n",
    "        score_sum = sum(ord(q) - 33 for q in trimmed_quality)\n",
    "        mean_score = round(score_sum / len(trimmed_quality))\n",
    "        return mean_score\n",
    "\n",
    "    def extracted_mirna_with_quality_score(self):\n",
    "        records = []\n",
    "        phred_scores = [0] * 100\n",
    "        with pysam.FastxFile(self.input_file) as f:\n",
    "            for record in f:\n",
    "                sequence = record.sequence\n",
    "                quality = record.quality\n",
    "                if sequence.count(self.adapter) > 0:\n",
    "                    trimmed_sequence = sequence.split(self.adapter, 1)[0]\n",
    "                    trimmed_quality = quality[:len(trimmed_sequence)]\n",
    "                else:\n",
    "                    trimmed_sequence = sequence\n",
    "                    trimmed_quality = quality\n",
    "                \n",
    "                if 30 >= len(trimmed_sequence) >= 12:\n",
    "                    mean_score = self.MeanPhredScore(trimmed_quality)\n",
    "                    phred_scores[int(mean_score)] += 1\n",
    "                    if mean_score >= 20:\n",
    "                        record_id = f\"{sample_name}-{len(records)}-score:{mean_score}\"\n",
    "                        records.append((record_id, trimmed_sequence))\n",
    "        for idx, count in enumerate(phred_scores):\n",
    "            if count > 0:\n",
    "                print(f\"Score {idx}: {count} sequences\")\n",
    "\n",
    "        with open(self.output_file, \"w\") as output:\n",
    "            SeqIO.write((SeqIO.SeqRecord(Seq(sequence), id=record_id, description=\"\") for record_id, sequence in records), output, \"fasta\")\n",
    "    \n",
    "    def modify_fasta_header(self):\n",
    "        output_records = []\n",
    "        with gzip.open(self.input_file, \"rt\") as f:\n",
    "            for record in SeqIO.parse(f, \"fasta\"):\n",
    "                record.id = f\"{sample_name}-{len(output_records)}-score:37\"\n",
    "                record.description = \"\"\n",
    "                output_records.append(record)\n",
    "        with open(self.output_file, \"w\") as f:\n",
    "            SeqIO.write(output_records, f, \"fasta\")\n",
    "    \n",
    "    def modify_fastq_header(self, tmp_path):\n",
    "        output_records = []\n",
    "        with gzip.open(tmp_path + '/' + sample_name + \"_trimmed.fq.gz\", \"rt\") as f:\n",
    "            for record in SeqIO.parse(f, \"fastq\"):\n",
    "                record.id = f\"{sample_name}-{len(output_records)}-score:37\"\n",
    "                record.description = \"\"\n",
    "                output_records.append(record)\n",
    "        with open(self.output_file, \"w\") as f:\n",
    "            SeqIO.write(output_records, f, \"fasta\")\n",
    "\n",
    "\n",
    "    def data_process(self):\n",
    "        log_file = open(self.log_file, \"w\")\n",
    "        print(f\"[{datetime.datetime.now()}] Start to trim the adapter and low quality reads!\")\n",
    "        fq_extensions = [\".fastq\", \".fq\", \".fastq.gz\", \".fq.gz\"]\n",
    "        fa_extensions = [\".fasta\", \".fa\", \".fasta.gz\", \".fa.gz\"]\n",
    "        if self.input_file.endswith(tuple(fq_extensions)) and self.flag == False:\n",
    "            self.extracted_mirna_with_quality_score()\n",
    "        elif self.input_file.endswith(tuple(fa_extensions)) and self.flag == False:\n",
    "            self.modify_fasta_header()\n",
    "        elif self.flag == True:\n",
    "            trim_cmd = \"trim_galore --fastqc --fastqc_args '-t 16 --nogroup' --gzip -q 20 --length 12 --max_length 30 --trim-n --basename {} --no_report_file  -j 8 -a {} -o {} {}\".format(self.sample_name, self.adapter, self.tmp_path, self.input_file)\n",
    "            subprocess.run(trim_cmd, check=True, shell=True, stdin = log_file, stderr= log_file)\n",
    "            self.modify_fastq_header(tmp_path)\n",
    "        else:\n",
    "            print(\"Please check your input file format!\")\n",
    "            exit(1)\n",
    "        log_file.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"/bios-store1/chenyc/Project/TRM-sRNA-seq/h67/1_rawdata/h-PB1_231215N_S36_L002_R1_001.fastq.gz\"\n",
    "    output_file = \"/bios-store1/chenyc/Project/TRM-sRNA-seq/h67/2_tailing_trimming/h-PB1_231215N_S36_L002_R1_001_trimmed.fasta\"\n",
    "    tmp_path = \"/bios-store1/chenyc/Project/TRM-sRNA-seq/h67/2_tailing_trimming\"\n",
    "    adapter = \"AACTGTAGGCACCATCAAT\"\n",
    "    sample_name = os.path.basename(input_file).split(\".\")[0].replace(\"-\", \"_\")\n",
    "    tag = input_file.split(\".\")[-1]\n",
    "    flag = True\n",
    "    \n",
    "    preprocess = Preprocess(input_file, output_file, tmp_path, adapter, sample_name, flag)\n",
    "    preprocess.data_process()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">EF-19_231201N_S2_L003_R1_001-0-score:32\n",
      "NAATACCGGGCTC\n",
      ">EF-19_231201N_S2_L003_R1_001-1-score:35\n",
      "NGTGTTTTCTAGTGTAGGATT\n",
      ">EF-19_231201N_S2_L003_R1_001-2-score:34\n",
      "NATAGCTTCGCAG\n",
      ">EF-19_231201N_S2_L003_R1_001-4-score:35\n",
      "NTTGGATTGAAGGGAGCTCTTC\n",
      ">EF-19_231201N_S2_L003_R1_001-5-score:35\n",
      "NATGAAAACGAAGAGAATCATAA\n",
      "--------------\n",
      ">EF-19_231201N_S2_L003_R1_001-0-score:32\n",
      "NAATACCGGGCTC\n",
      ">EF-19_231201N_S2_L003_R1_001-1-score:35\n",
      "NGTGTTTTCTAGTGTAGGATT\n",
      ">EF-19_231201N_S2_L003_R1_001-2-score:34\n",
      "NATAGCTTCGCAG\n",
      ">EF-19_231201N_S2_L003_R1_001-3-score:35\n",
      "NTTGGATTGAAGGGAGCTCTTC\n",
      ">EF-19_231201N_S2_L003_R1_001-4-score:35\n",
      "NATGAAAACGAAGAGAATCATAA\n",
      "--------------\n",
      ">EF-19_231201N_S2_L003_R1_001-0-score:37\n",
      "AATACCGGGCTC\n",
      ">EF-19_231201N_S2_L003_R1_001-1-score:37\n",
      "GTGTTTTCTAGTGTAGGATT\n",
      ">EF-19_231201N_S2_L003_R1_001-2-score:37\n",
      "ATAGCTTCGCAG\n",
      ">EF-19_231201N_S2_L003_R1_001-3-score:37\n",
      "TTGGATTGAAGGGAGCTCTTC\n",
      ">EF-19_231201N_S2_L003_R1_001-4-score:37\n",
      "ATGAAAACGAAGAGAATCATAA\n",
      "--------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25262310 /bios-store1/chenyc/Project/TMM/Project_tianmiaomiao_231201N/3_tailing_trimming/2_cleandata/EF-19_231201N_S2_L003_R1_001.fasta\n",
      "--------------\n",
      "25230746 /bios-store1/chenyc/scripts/Tailing_Trimming/test/test.fasta\n",
      "--------------\n",
      "25517692 /bios-store1/chenyc/scripts/Tailing_Trimming/test/test_ef.fasta\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head /bios-store1/chenyc/Project/TMM/Project_tianmiaomiao_231201N/3_tailing_trimming/2_cleandata/EF-19_231201N_S2_L003_R1_001.fasta\n",
    "echo \"--------------\"\n",
    "head /bios-store1/chenyc/scripts/Tailing_Trimming/test/test.fasta\n",
    "echo \"--------------\"\n",
    "head  /bios-store1/chenyc/scripts/Tailing_Trimming/test/test_ef.fasta\n",
    "echo \"--------------\"\n",
    "wc -l  /bios-store1/chenyc/Project/TMM/Project_tianmiaomiao_231201N/3_tailing_trimming/2_cleandata/EF-19_231201N_S2_L003_R1_001.fasta\n",
    "echo \"--------------\"\n",
    "wc -l /bios-store1/chenyc/scripts/Tailing_Trimming/test/test.fasta\n",
    "echo \"--------------\"\n",
    "wc -l /bios-store1/chenyc/scripts/Tailing_Trimming/test/test_ef.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-14 23:36:53.860786] Start to remapping the reads!\n",
      "[2024-01-14 23:36:53.860834] Reformatting fasta header\n",
      "Mapping whole reads to trsnoRNA and unmapped reads are saved to /bios-store1/chenyc/Project/TRM-sRNA-seq/h67/2_tailing_trimming/clean.fasta\n",
      "Mapping whole reads to hairpin20 and unmapped reads are saved to /bios-store1/chenyc/Project/TRM-sRNA-seq/h67/2_tailing_trimming/unmapped-0.fasta\n",
      "Trimming 1 bp for each unmapped reads\n",
      "Mapping trimmed 1 bp reads to hairpin20 and unmapped reads are saved to /bios-store1/chenyc/Project/TRM-sRNA-seq/h67/2_tailing_trimming/unmapped-1.fasta\n",
      "Trimming 2 bp for each unmapped reads\n",
      "Mapping trimmed 2 bp reads to hairpin20 and unmapped reads are saved to /bios-store1/chenyc/Project/TRM-sRNA-seq/h67/2_tailing_trimming/unmapped-2.fasta\n",
      "Trimming 3 bp for each unmapped reads\n",
      "Mapping trimmed 3 bp reads to hairpin20 and unmapped reads are saved to /bios-store1/chenyc/Project/TRM-sRNA-seq/h67/2_tailing_trimming/unmapped-3.fasta\n",
      "Trimming 4 bp for each unmapped reads\n",
      "Mapping trimmed 4 bp reads to hairpin20 and unmapped reads are saved to /bios-store1/chenyc/Project/TRM-sRNA-seq/h67/2_tailing_trimming/unmapped-4.fasta\n",
      "Trimming 5 bp for each unmapped reads\n",
      "Mapping trimmed 5 bp reads to hairpin20 and unmapped reads are saved to /bios-store1/chenyc/Project/TRM-sRNA-seq/h67/2_tailing_trimming/unmapped-5.fasta\n",
      "Trimming 6 bp for each unmapped reads\n",
      "Mapping trimmed 6 bp reads to hairpin20 and unmapped reads are saved to /bios-store1/chenyc/Project/TRM-sRNA-seq/h67/2_tailing_trimming/unmapped-6.fasta\n",
      "Trimming 7 bp for each unmapped reads\n",
      "Mapping trimmed 7 bp reads to hairpin20 and unmapped reads are saved to /bios-store1/chenyc/Project/TRM-sRNA-seq/h67/2_tailing_trimming/unmapped-7.fasta\n",
      "Trimming 8 bp for each unmapped reads\n",
      "Mapping trimmed 8 bp reads to hairpin20 and unmapped reads are saved to /bios-store1/chenyc/Project/TRM-sRNA-seq/h67/2_tailing_trimming/unmapped-8.fasta\n",
      "Trimming 9 bp for each unmapped reads\n",
      "Mapping trimmed 9 bp reads to hairpin20 and unmapped reads are saved to /bios-store1/chenyc/Project/TRM-sRNA-seq/h67/2_tailing_trimming/unmapped-9.fasta\n",
      "Trimming 10 bp for each unmapped reads\n",
      "Mapping trimmed 10 bp reads to hairpin20 and unmapped reads are saved to /bios-store1/chenyc/Project/TRM-sRNA-seq/h67/2_tailing_trimming/unmapped-10.fasta\n",
      "Processing: /bios-store1/chenyc/Project/TRM-sRNA-seq/h67/2_tailing_trimming/mapped-0.sam\n",
      "Processing: /bios-store1/chenyc/Project/TRM-sRNA-seq/h67/2_tailing_trimming/mapped-1.sam\n",
      "Processing: /bios-store1/chenyc/Project/TRM-sRNA-seq/h67/2_tailing_trimming/mapped-2.sam\n",
      "Processing: /bios-store1/chenyc/Project/TRM-sRNA-seq/h67/2_tailing_trimming/mapped-3.sam\n",
      "Processing: /bios-store1/chenyc/Project/TRM-sRNA-seq/h67/2_tailing_trimming/mapped-4.sam\n",
      "Processing: /bios-store1/chenyc/Project/TRM-sRNA-seq/h67/2_tailing_trimming/mapped-5.sam\n",
      "Processing: /bios-store1/chenyc/Project/TRM-sRNA-seq/h67/2_tailing_trimming/mapped-6.sam\n",
      "Processing: /bios-store1/chenyc/Project/TRM-sRNA-seq/h67/2_tailing_trimming/mapped-7.sam\n",
      "Processing: /bios-store1/chenyc/Project/TRM-sRNA-seq/h67/2_tailing_trimming/mapped-8.sam\n",
      "Processing: /bios-store1/chenyc/Project/TRM-sRNA-seq/h67/2_tailing_trimming/mapped-9.sam\n",
      "Processing: /bios-store1/chenyc/Project/TRM-sRNA-seq/h67/2_tailing_trimming/mapped-10.sam\n",
      "[2024-01-15 00:09:42.845859] Merging bam files\n",
      "[2024-01-15 00:09:58.523852] Remapping finished!\n"
     ]
    }
   ],
   "source": [
    "class Remapping:\n",
    "    def __init__(self, output_file, tmp_path, reference, trsnorna, sample_name):\n",
    "        self.output_file = output_file\n",
    "        self.tmp_path = tmp_path\n",
    "        self.reference = reference\n",
    "        self.trsnoRNA = trsnorna\n",
    "        self.sample_name = sample_name\n",
    "        self.unmapped2genome = os.path.join(tmp_path, \"unmapped-to-genome.fasta\")\n",
    "        self.unmapped2trsnorna = os.path.join(tmp_path, \"clean.fasta\")\n",
    "        self.log_file = os.path.join(tmp_path, \"log_remapping.txt\")\n",
    "\n",
    "    def reformatting_fasta(self):\n",
    "        print(f\"[{datetime.datetime.now()}] Reformatting fasta header\")\n",
    "        output_records = []\n",
    "        with open(self.output_file, \"r\") as f:\n",
    "            for record in SeqIO.parse(f, \"fasta\"):\n",
    "                record.id = record.id.replace(\"-score:37\", f\"-{record.seq}--0\")\n",
    "                record.description = \"\"\n",
    "                output_records.append(record)\n",
    "        with open(self.unmapped2genome, \"w\") as f:\n",
    "            SeqIO.write(output_records, f, \"fasta\")\n",
    "\n",
    "    def remapping(self):\n",
    "        log_file = open(self.log_file, \"w\")\n",
    "        print(f\"Mapping whole reads to trsnoRNA and unmapped reads are saved to {self.tmp_path}/clean.fasta\")\n",
    "        mapping_cmd = \"bowtie -p 24 -v 0 -S -a -x {} -f {} --un {}/clean.fasta {}/map2trsnoRNA.sam\".format(self.trsnoRNA, self.unmapped2genome, self.tmp_path, self.tmp_path)\n",
    "        subprocess.run(mapping_cmd, check=True, shell=True, stderr=log_file, stdout=log_file)\n",
    "        print(f\"Mapping whole reads to hairpin20 and unmapped reads are saved to {self.tmp_path}/unmapped-0.fasta\")\n",
    "        mapping_cmd = \"bowtie -p 24 -v 0 -S -a -x {} -f {} --un {}/unmapped-0.fasta {}/mapped-0.sam\".format(self.reference, self.unmapped2trsnorna, self.tmp_path, self.tmp_path)\n",
    "        subprocess.run(mapping_cmd, check=True, shell=True, stderr=log_file, stdout=log_file)\n",
    "\n",
    "        for i in range(1, 11):\n",
    "            k = i - 1\n",
    "            output_records = []\n",
    "            print(f\"Trimming {i} bp for each unmapped reads\")\n",
    "            with open(f\"{self.tmp_path}/unmapped-{k}.fasta\", \"r\") as in_file:\n",
    "                for record in SeqIO.parse(in_file, \"fasta\"):\n",
    "                    record.seq = record.seq[:-1]\n",
    "                    if len(record.seq) >= 12:\n",
    "                        record.id = record.id.split(\"--\")[0] + f\"--{i}\"\n",
    "                        output_records.append(record)\n",
    "\n",
    "            with open(f\"{self.tmp_path}/trimmed-{i}.fasta\", \"w\") as out_file:\n",
    "                SeqIO.write(output_records, out_file, \"fasta\")\n",
    "            \n",
    "            print(f\"Mapping trimmed {i} bp reads to hairpin20 and unmapped reads are saved to {tmp_path}/unmapped-{i}.fasta\")\n",
    "            remapping_cmd = \"bowtie -p 24 -v 0 -S -a --norc --no-unal -x {} -f {}/trimmed-{}.fasta --un {}/unmapped-{}.fasta {}/mapped-{}.sam\".format(self.reference, self.tmp_path, i, self.tmp_path, i, self.tmp_path, i)\n",
    "            subprocess.run(remapping_cmd, check=True, shell=True, stderr=log_file, stdout=log_file)\n",
    "        log_file.close()\n",
    "        \n",
    "\n",
    "    def merge_result(self):\n",
    "        for i in range(0, 11):\n",
    "            print(f\"Processing: {self.tmp_path}/mapped-{i}.sam\")\n",
    "            with pysam.AlignmentFile(f\"{self.tmp_path}/mapped-{i}.sam\", \"r\", threads=24) as in_file:\n",
    "                with pysam.AlignmentFile(f\"{self.tmp_path}/mapped-{i}.bam\", \"wb\", template=in_file, threads=24) as out_file:\n",
    "                    for record in in_file:\n",
    "                        record.query_sequence = record.query_name.split(\"-\")[-3]\n",
    "                        record.template_length = len(record.query_sequence)\n",
    "                        record.cigartuples = [(0, len(record.query_sequence))]\n",
    "                        trim_nu = record.query_sequence[-int(record.query_name.split(\"--\")[1]):]\n",
    "                        record.set_tag(\"TM\", trim_nu)\n",
    "                        out_file.write(record)\n",
    "            pysam.sort(\"-@\", \"24\", \"-o\", f\"{self.tmp_path}/mapped-{i}.sorted.bam\", f\"{self.tmp_path}/mapped-{i}.bam\")\n",
    "            pysam.index(f\"{self.tmp_path}/mapped-{i}.sorted.bam\")\n",
    "            os.remove(f\"{self.tmp_path}/mapped-{i}.sam\")\n",
    "        print(f\"[{datetime.datetime.now()}] Merging bam files\")\n",
    "        bam_files = glob.glob(f\"{self.tmp_path}/mapped-*.sorted.bam\")\n",
    "        if len(bam_files) > 0:\n",
    "            pysam.merge(\"-@\", \"24\", \"-f\", f\"{self.tmp_path}/merged-alignment-sorted.sam\", *bam_files)\n",
    "        else:\n",
    "            print(\"No bam files found for merging\")\n",
    "    \n",
    "    def data_process(self):\n",
    "        print(f\"[{datetime.datetime.now()}] Start to remapping the reads!\")\n",
    "        self.reformatting_fasta()\n",
    "        self.remapping()\n",
    "        self.merge_result()\n",
    "        print(f\"[{datetime.datetime.now()}] Remapping finished!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    reference = \"/bios-store1/chenyc/Reference_Source/Arabidopsis_Reference/ath_hairpin_bowtie_index/hairpin\"\n",
    "    trsnoRNA = \"/bios-store1/chenyc/Reference_Source/Arabidopsis_Reference/ath_trsnoRNA_bowtie_index/trsnoRNA\"\n",
    "    input_file = \"/bios-store1/chenyc/Project/TRM-sRNA-seq/h67/1_rawdata/h-PB1_231215N_S36_L002_R1_001.fastq.gz\"\n",
    "    output_file = \"/bios-store1/chenyc/Project/TRM-sRNA-seq/h67/2_tailing_trimming/h-PB1_231215N_S36_L002_R1_001_trimmed.fasta\"\n",
    "    tmp_path = \"/bios-store1/chenyc/Project/TRM-sRNA-seq/h67/2_tailing_trimming\"\n",
    "    adapter = \"AACTGTAGGCAC\"\n",
    "    sample_name = os.path.basename(input_file).split(\".\")[0].replace(\"-\", \"_\")\n",
    "    tag = input_file.split(\".\")[-1]\n",
    "    flag = True\n",
    "    \n",
    "    remapping = Remapping(output_file, tmp_path, reference, trsnoRNA, sample_name)\n",
    "    remapping.data_process()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTDIR = \"/bios-store1/chenyc/Project/TRM-sRNA-seq/h67/3_remapping\"\n",
    "PROFILE_PATH = os.path.join(OUTDIR, \"4_163.results\")\n",
    "SUMMARY_PATH = os.path.join(OUTDIR, \"5_GMC_analysis\")\n",
    "class Profile_maker:\n",
    "    def __init__(self, meta_file, input_file, output_path, sample_name):\n",
    "        self.metafile = meta_file\n",
    "        self.script = os.path.join(os.path.dirname(__file__), \"4_163-profile.pl\")\n",
    "        self.output_path = output_path\n",
    "        self.input_file = input_file # remapping result: merged-alignment-sorted.sam\n",
    "        self.output_file = os.path.join(self.output_path, sample_name + \".txt\")\n",
    "        \n",
    "    def dyc_163_profile(self):\n",
    "        print(f\"[{datetime.datetime.now()}] Start to generate the miRNA profile!\")\n",
    "        with open(self.output_file, \"w\") as f:\n",
    "            profile_cmd = f\"perl self.script {self.metafile} {self.input_file}\"\n",
    "            subprocess.run(profile_cmd, check=True, shell=True, stdout=f)\n",
    "        print(f\"[{datetime.datetime.now()}] Profile generated!\")\n",
    "\n",
    "    def split_163_file(self):\n",
    "        print(f\"[{datetime.datetime.now()}] Start to split the 163 profile file!\")\n",
    "        with open(self.output_file, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "        matrix = [line.strip().split('\\t') for line in lines]\n",
    "        groups = [matrix[i:i+12] for i in range(0, len(matrix), 12)]\n",
    "        for group in groups:\n",
    "            last_line = group.pop()\n",
    "            newgroup = [row[3:] for row in group[3:]]\n",
    "            newgroup.insert(0, last_line) \n",
    "            group.insert(0, last_line) \n",
    "            new_filename = newgroup[0][0].split()[0].replace(\"*\", \"_star\") + \".txt\"\n",
    "            file = os.path.join(self.output_path, sample_name, new_filename)\n",
    "            with open(file, \"w\") as f:\n",
    "                f.write('\\t\\n'.join(['\\t'.join(row) for row in group]) + '\\t\\n')\n",
    "\n",
    "    def martix_summary(self):\n",
    "        n_lines = len(open(self.output_file, 'r').readlines())\n",
    "        n_groups = int(n_lines/12)\n",
    "        res = []\n",
    "        for i in range(n_groups):\n",
    "            temp_res = []\n",
    "            matrix_data = np.loadtxt(self.output_file, skiprows=i*12, max_rows=11)\n",
    "            tag_data = np.loadtxt(self.output_file, skiprows=i*12+11, max_rows=1, dtype=str)[0]\n",
    "            temp_res.append(tag_data)\n",
    "            sum_all = np.sum(matrix_data)\n",
    "            temp_res.append(sum_all)\n",
    "            temp_res.append(str(sum_all - np.sum(matrix_data[:,10])))\n",
    "            temp_res.append(str(sum_all - np.sum(matrix_data[10,:])))\n",
    "            # for j in range(10):\n",
    "            for j in range(9,-1,-1):\n",
    "                temp_res.append(str(np.sum(matrix_data[j,:])))\n",
    "            res.append(temp_res)\n",
    "\n",
    "        res = np.array(res)\n",
    "        np.savetxt(os.path.join(self.output_path, sample_name + \".summary.txt\"), res, fmt=\"%s\", delimiter = \"\\t\",\n",
    "                    header = \"ID\\tSUM\\ttrimming\\ttailling\\ttail_1\\ttail_2\\ttail_3\\ttail_4\\ttail_5\\ttail_6\\ttail_7\\ttail_8\\ttail_9\\ttail_10\")\n",
    "\n",
    "class Profile_summary:\n",
    "    def __init__(self, meta_file, input_file, output_path, sample_name):\n",
    "        self.metafile = meta_file\n",
    "        self.sample_name = sample_name\n",
    "        self.input_file = input_file # remapping result: merged-alignment-sorted.sam\n",
    "        self.output_path = output_path\n",
    "\n",
    "    def get_mirna_5GMC_reads(self):\n",
    "        id = []\n",
    "        site = []\n",
    "        with open(self.metafile, mode='r') as f:\n",
    "            data = csv.reader(f, delimiter='\\t')\n",
    "            for d in data:\n",
    "                id.append(d[0])\n",
    "                site.append(d[2])\n",
    "        f.close()\n",
    "\n",
    "        out = []\n",
    "        with open(self.input_file, mode='r') as f:\n",
    "            data = csv.reader(f, delimiter='\\t')\n",
    "            for d in data:\n",
    "                for i, s in zip(id, site):\n",
    "                    if i.startswith(d[2]) and d[3] == s:\n",
    "                        d[2] = i\n",
    "                        if d[2] == '16':\n",
    "                            d[9] = reverse_complement(d[9])\n",
    "                        new_line = '\\t'.join([d[0], d[2], d[3], d[9]]) + '\\n'\n",
    "                        out.append(new_line)\n",
    "                        break\n",
    "        f.close()\n",
    "        \n",
    "        output_file = os.path.join(self.output_path, sample_name + \".5GMC\")\n",
    "        header = \"RNAME\\tID\\tStart\\tSequence\\n\"\n",
    "        out.insert(0, header)\n",
    "        with open(output_file, 'w') as f:\n",
    "            f.writelines(out)\n",
    "        return output_file\n",
    "\n",
    "    def get_mirna_5GMC_sequence(self, output_file):\n",
    "        df = pd.read_csv(output_file, sep='\\t')\n",
    "        groups = df.groupby(df.columns[1])\n",
    "        for name, group in groups:\n",
    "            filename = os.path.join(self.output_path, \"doc_seqlogo\", sample_name, name.replace(\"*\", \"_star\") + \".txt\")\n",
    "            group.iloc[:, 3].apply(lambda x: x.replace('T', 'U')).to_csv(filename, sep='\\t', index=False, header=False)\n",
    "\n",
    "        with open(self.metafile, 'r') as f:\n",
    "            for line in f:\n",
    "                file_name = line.strip().split(\"\\t\")[0].replace(\"*\",\"_star\")\n",
    "                file_path = os.path.join(self.output_path, file_name + \".txt\")\n",
    "                if not os.path.exists(file_path):\n",
    "                    with open(file_path, 'w') as f:\n",
    "                        f.write('N'*30)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetune",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
